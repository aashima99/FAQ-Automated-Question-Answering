{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Question Answering from FAQs Using Word-Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The basic idea of this project is to automatically retrieve a suitable response to customer questions from FAQs. Often websites have  comprehensive FAQs, but manually searching and finding the answer to a specific question from these FAQs is not trivial. The purpose of this exercise is to answer user queries by automatically retrieving the closest question and answer from predefined FAQs when appropriate. I will be using a dataset of FAQs which I have made myself by searching the most frequently asked question from the Internet.The basic strategy to this will be finding an FAQ question that is closest in meaning to the user query and then it will display to the user. For this, the efficient way of computing the semantic similarity between two sentences is converting each sentence into vectors and then using cosine similarity between the vectors to come up with a distance measure between sentences that indicates how similar they are in meaning and for this I have used various models which is further explained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FAQs.csv\");\n",
    "df.columns=[\"Questions\",\"Answers\"];\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most NLP tasks involve preprocessing.\n",
    "- Removing all characters that are not alpha numeric\n",
    "- Removing stopwords - commonly used words such as 'a', 'to', 'in' and so on.. that do not contribute to the semantic similarity between two sentences.\n",
    "##### We apply this to both the FAQ questions and the user query sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what does the job hunting experience look like  ', 'what are the most valuable skills for a data scientist ', 'what is the average salary of a data scientist ', 'what are the top algorithms that every data scientist should have in his her toolbox ', 'how to prepare for a data science interview ', 'any insights you can offer about the ds job market   ', 'do employers look for an advanced ml degree  ', 'how does a typical day of a data scientist look like ', 'do i need to prepare algorithms and data structures for a data science interview   ', 'what are the benefits of a data science certification ', 'should i participate in hackathons  will that help me in getting a job ', 'do i need to know statistics in order to land a data science role ', 'what are the career opportunities in data science ', 'what are the most common mistakes data science enthusiasts make in an interview ', 'what s the impact of covid on hiring for ds roles ', 'what skills and qualities do employers look for in a data scientist ', 'how proficient should a data scientist be in coding ', 'what are the various rounds in a data scientist interview   ', 'what is the mathematical background required for a data scientist  ']\n",
      "\n",
      "['job hunting experience look like', 'valuable skills data scientist', 'average salary data scientist', 'algorithms data scientist toolbox', 'prepare data science interview', 'insights offer ds job market', 'employers look advanced ml degree', 'typical day data scientist look like', 'need prepare algorithms data structures data science interview', 'benefits data science certification', 'participate hackathons help getting job', 'need know statistics order land data science role', 'career opportunities data science', 'common mistakes data science enthusiasts interview', 's impact covid hiring ds roles', 'skills qualities employers look data scientist', 'proficient data scientist coding', 'rounds data scientist interview', 'mathematical background required data scientist']\n"
     ]
    }
   ],
   "source": [
    "wordnet=WordNetLemmatizer()\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "def preprocess(ab):\n",
    "  ab = re.sub('[^a-zA-Z]', ' ', ab)\n",
    "  ab = ab.lower()              \n",
    "  return ab\n",
    "\n",
    "questions=[]\n",
    "for i in range(0, len(df)):\n",
    "  ab = preprocess(df['Questions'][i])\n",
    "  questions.append(ab)\n",
    "print(questions);\n",
    "sentence_words = [[word for word in document.split()]\n",
    "                    for document in questions]\n",
    "\n",
    "print()\n",
    "#sentences = nltk.sent_tokenize(paragraph)\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#for i in range(len(sentences)):\n",
    "    #words = nltk.word_tokenize(sentences[i])\n",
    "    #words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    #sentences[i] = ' '.join(words)  \n",
    "    \n",
    "def preprocess_without_stopwords(ab):\n",
    "  corpus=[]\n",
    "  ab = re.sub('[^a-zA-Z]', ' ', ab)\n",
    "  ab = ab.lower()\n",
    "  ab = remove_stopwords(ab)\n",
    "  return ab\n",
    "\n",
    "cleaned_sentences=[]\n",
    "for i in range(0, len(df)):\n",
    "  ab = preprocess_without_stopwords(df['Questions'][i])\n",
    "  cleaned_sentences.append(ab) \n",
    "print(cleaned_sentences);   \n",
    " \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first model I am using for semantic similarity is  Bag of Words (BOW). With BOW, each sentence is encoded into a vector whose length is the number of words in the vocabulary. Each element of the vector indicates how many times the particular word occurs in the sentence. An example is shown below by printing the dictionary and the FAQ questions in the BOW sparse format. The vector representation is also called \"Embedding\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  does\n",
      "1  :  experience\n",
      "2  :  hunting\n",
      "3  :  job\n",
      "4  :  like\n",
      "5  :  look\n",
      "6  :  the\n",
      "7  :  what\n",
      "8  :  a\n",
      "9  :  are\n",
      "10  :  data\n",
      "11  :  for\n",
      "12  :  most\n",
      "13  :  scientist\n",
      "14  :  skills\n",
      "15  :  valuable\n",
      "16  :  average\n",
      "17  :  is\n",
      "18  :  of\n",
      "19  :  salary\n",
      "20  :  algorithms\n",
      "21  :  every\n",
      "22  :  have\n",
      "23  :  her\n",
      "24  :  his\n",
      "25  :  in\n",
      "26  :  should\n",
      "27  :  that\n",
      "28  :  toolbox\n",
      "29  :  top\n",
      "30  :  how\n",
      "31  :  interview\n",
      "32  :  prepare\n",
      "33  :  science\n",
      "34  :  to\n",
      "35  :  about\n",
      "36  :  any\n",
      "37  :  can\n",
      "38  :  ds\n",
      "39  :  insights\n",
      "40  :  market\n",
      "41  :  offer\n",
      "42  :  you\n",
      "43  :  advanced\n",
      "44  :  an\n",
      "45  :  degree\n",
      "46  :  do\n",
      "47  :  employers\n",
      "48  :  ml\n",
      "49  :  day\n",
      "50  :  typical\n",
      "51  :  and\n",
      "52  :  i\n",
      "53  :  need\n",
      "54  :  structures\n",
      "55  :  benefits\n",
      "56  :  certification\n",
      "57  :  getting\n",
      "58  :  hackathons\n",
      "59  :  help\n",
      "60  :  me\n",
      "61  :  participate\n",
      "62  :  will\n",
      "63  :  know\n",
      "64  :  land\n",
      "65  :  order\n",
      "66  :  role\n",
      "67  :  statistics\n",
      "68  :  career\n",
      "69  :  opportunities\n",
      "70  :  common\n",
      "71  :  enthusiasts\n",
      "72  :  make\n",
      "73  :  mistakes\n",
      "74  :  covid\n",
      "75  :  hiring\n",
      "76  :  impact\n",
      "77  :  on\n",
      "78  :  roles\n",
      "79  :  s\n",
      "80  :  qualities\n",
      "81  :  be\n",
      "82  :  coding\n",
      "83  :  proficient\n",
      "84  :  rounds\n",
      "85  :  various\n",
      "86  :  background\n",
      "87  :  mathematical\n",
      "88  :  required\n",
      "job hunting experience look like\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "valuable skills data scientist\n",
      "[(6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)]\n",
      "average salary data scientist\n",
      "[(6, 1), (7, 1), (8, 1), (10, 1), (13, 1), (16, 1), (17, 1), (18, 1), (19, 1)]\n",
      "algorithms data scientist toolbox\n",
      "[(6, 1), (7, 1), (9, 1), (10, 1), (13, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)]\n",
      "prepare data science interview\n",
      "[(8, 1), (10, 1), (11, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)]\n",
      "insights offer ds job market\n",
      "[(3, 1), (6, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1)]\n",
      "employers look advanced ml degree\n",
      "[(5, 1), (11, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1)]\n",
      "typical day data scientist look like\n",
      "[(0, 1), (4, 1), (5, 1), (8, 2), (10, 1), (13, 1), (18, 1), (30, 1), (49, 1), (50, 1)]\n",
      "need prepare algorithms data structures data science interview\n",
      "[(8, 1), (10, 2), (11, 1), (20, 1), (31, 1), (32, 1), (33, 1), (34, 1), (46, 1), (51, 1), (52, 1), (53, 1), (54, 1)]\n",
      "benefits data science certification\n",
      "[(6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (18, 1), (33, 1), (55, 1), (56, 1)]\n",
      "participate hackathons help getting job\n",
      "[(3, 1), (8, 1), (25, 2), (26, 1), (27, 1), (52, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1)]\n",
      "need know statistics order land data science role\n",
      "[(8, 1), (10, 1), (25, 1), (33, 1), (34, 2), (46, 1), (52, 1), (53, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1)]\n",
      "career opportunities data science\n",
      "[(6, 1), (7, 1), (9, 1), (10, 1), (25, 1), (33, 1), (68, 1), (69, 1)]\n",
      "common mistakes data science enthusiasts interview\n",
      "[(6, 1), (7, 1), (9, 1), (10, 1), (12, 1), (25, 1), (31, 1), (33, 1), (44, 1), (70, 1), (71, 1), (72, 1), (73, 1)]\n",
      "s impact covid hiring ds roles\n",
      "[(6, 1), (7, 1), (11, 1), (18, 1), (38, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1)]\n",
      "skills qualities employers look data scientist\n",
      "[(5, 1), (7, 1), (8, 1), (10, 1), (11, 1), (13, 1), (14, 1), (25, 1), (46, 1), (47, 1), (51, 1), (80, 1)]\n",
      "proficient data scientist coding\n",
      "[(8, 1), (10, 1), (13, 1), (25, 1), (26, 1), (30, 1), (81, 1), (82, 1), (83, 1)]\n",
      "rounds data scientist interview\n",
      "[(6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (13, 1), (25, 1), (31, 1), (84, 1), (85, 1)]\n",
      "mathematical background required data scientist\n",
      "[(6, 1), (7, 1), (8, 1), (10, 1), (11, 1), (13, 1), (17, 1), (86, 1), (87, 1), (88, 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(sentence_words)\n",
    "for key, value in dictionary.items():\n",
    "    print(key, ' : ', value)\n",
    "\n",
    "import pprint\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in sentence_words]\n",
    "for sent,embedding in zip(questions,bow_corpus):\n",
    "    print(sent)\n",
    "    print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " is coding required for becoming data scientist  \n",
      " [(10, 1), (11, 1), (13, 1), (17, 1), (82, 1), (88, 1)]\n"
     ]
    }
   ],
   "source": [
    "question_orig=\"Is Coding required for becoming data scientist?\"\n",
    "question=preprocess(question_orig)\n",
    "question_embedding = dictionary.doc2bow(question.split())\n",
    "\n",
    "print(\"\\n\\n\",question,\"\\n\",question_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Similarity using \"Cosine Similarity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09950371902099892 what does the job hunting experience look like  \n",
      "1 0.9978569490503114 what are the most valuable skills for a data scientist \n",
      "2 0.9978569490503114 what is the average salary of a data scientist \n",
      "3 0.9978569490503114 what are the top algorithms that every data scientist should have in his her toolbox \n",
      "4 0.9996953077321108 how to prepare for a data science interview \n",
      "5 0.9754410020677066 any insights you can offer about the ds job market   \n",
      "6 0.9952285251199801 do employers look for an advanced ml degree  \n",
      "7 0.09950371902099892 how does a typical day of a data scientist look like \n",
      "8 0.9996953077321108 do i need to prepare algorithms and data structures for a data science interview   \n",
      "9 0.9978569490503114 what are the benefits of a data science certification \n",
      "10 0.9754410020677066 should i participate in hackathons  will that help me in getting a job \n",
      "11 0.9996953077321108 do i need to know statistics in order to land a data science role \n",
      "12 0.9978569490503114 what are the career opportunities in data science \n",
      "13 0.9978569490503114 what are the most common mistakes data science enthusiasts make in an interview \n",
      "14 0.9978569490503114 what s the impact of covid on hiring for ds roles \n",
      "15 0.9952285251199801 what skills and qualities do employers look for in a data scientist \n",
      "16 0.9996953077321108 how proficient should a data scientist be in coding \n",
      "17 0.9978569490503114 what are the various rounds in a data scientist interview   \n",
      "18 0.9978569490503114 what is the mathematical background required for a data scientist  \n",
      "\n",
      "\n",
      "Question:  is coding required for becoming data scientist \n",
      "\n",
      "\n",
      "Retrieved:  How to prepare for a data science interview?\n",
      "Cracking any interview requires preparation and in the case of data science it is not restricted to performing well on the big day alone. An aspiring data scientist is expected to prepare across multiple fronts like:\n",
      "\n",
      "Build a portfolio of projects and MOOCs\n",
      "Network with peers and stay up-to-date with who’s who, follow trends\n",
      "Learn about the position that you are applying for\n",
      "Go through questions asked in previous interviews\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(question_embedding, sentence_embeddings, FAQdf, questions):\n",
    "  max_sim=-1;\n",
    "  index_sim=-1;\n",
    "  for index, faq_embedding in enumerate(sentence_embeddings):\n",
    "    sim = cosine_similarity(faq_embedding, question_embedding)[0][0];\n",
    "    print(index, sim, questions[index])\n",
    "    if sim>max_sim:\n",
    "      max_sim=sim;\n",
    "      index_sim=index;\n",
    "  print(\"\\n\")\n",
    "  print(\"Question: \",question)\n",
    "  print(\"\\n\");\n",
    "  print(\"Retrieved: \",FAQdf.iloc[index_sim,0]) \n",
    "  print(FAQdf.iloc[index_sim,1])\n",
    "\n",
    "calculate_similarity(question_embedding, bow_corpus, df, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec embeddings are popularly trained using the skipgram model. These embeddings are trained to take a word as input and reconstruct its context. As a result, they are able to take into account semantic similarity of words based on context information. The resulting embeddings are such that words with similar meaning tend to be closer in terms of cosine similarity.\n",
    "#### The most popular word2vec model is the skipgram model. Particularly, the most commonly used pre-trained model is based on the Google News dataset that has 3 billion running words and creates upto 300 dimensional embedding for 3 Million words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved glove model\n",
      "Saved glove model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec \n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "glove_model=None;\n",
    "try:\n",
    "    glove_model = gensim.models.KeyedVectors.load(\"./glovemodel.mod\")\n",
    "    print(\"Loaded glove model\")\n",
    "except:            \n",
    "    glove_model = api.load('glove-twitter-25')\n",
    "    glove_model.save(\"./glovemodel.mod\")\n",
    "    print(\"Saved glove model\")\n",
    "    \n",
    "v2w_model=None;\n",
    "try:\n",
    "    v2w_model = gensim.models.KeyedVectors.load(\"./w2vecmodel.mod\")\n",
    "    print(\"Loaded w2v model\")\n",
    "except:            \n",
    "    v2w_model = api.load('word2vec-google-news-300')\n",
    "    v2w_model.save(\"./w2vecmodel.mod\")\n",
    "    print(\"Saved glove model\")\n",
    "\n",
    "w2vec_embedding_size=len(v2w_model['computer']);\n",
    "glove_embedding_size=len(glove_model['computer']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Phrase Embeddings from Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To find phrase embeddings, there are sevaral specialized techniques. The most simple technique to convert word embeddings to phrase embeddings, that is applicable with word2vec and glove embeddings, is to sum up the individual word embeddings in the phrase to get a phrase vector which is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def getWordVec(word,model):\n",
    "        samp=model['computer'];\n",
    "        vec=[0]*len(samp);\n",
    "        try:\n",
    "                vec=model[word];\n",
    "        except:\n",
    "                vec=[0]*len(samp);\n",
    "        return (vec)\n",
    "\n",
    "\n",
    "def getPhraseEmbedding(phrase,embeddingmodel):\n",
    "                       \n",
    "        samp=getWordVec('computer', embeddingmodel);\n",
    "        vec=numpy.array([0]*len(samp));\n",
    "        den=0;\n",
    "        for word in phrase.split():\n",
    "            #print(word)\n",
    "            den=den+1;\n",
    "            vec=vec+numpy.array(getWordVec(word,embeddingmodel));\n",
    "        #vec=vec/den;\n",
    "        #return (vec.tolist());\n",
    "        return vec.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2859340695245002 job hunting experience look like\n",
      "1 0.6399762007455526 valuable skills data scientist\n",
      "2 0.5515435515887862 average salary data scientist\n",
      "3 0.6785673174335114 algorithms data scientist toolbox\n",
      "4 0.5518619953407247 prepare data science interview\n",
      "5 0.3603353703747457 insights offer ds job market\n",
      "6 0.3369262291158942 employers look advanced ml degree\n",
      "7 0.6239160348568386 typical day data scientist look like\n",
      "8 0.68063636350156 need prepare algorithms data structures data science interview\n",
      "9 0.6335812632832891 benefits data science certification\n",
      "10 0.408421370741606 participate hackathons help getting job\n",
      "11 0.599818270201776 need know statistics order land data science role\n",
      "12 0.48983332662133156 career opportunities data science\n",
      "13 0.5508442795886829 common mistakes data science enthusiasts interview\n",
      "14 0.31511008096839943 s impact covid hiring ds roles\n",
      "15 0.5408527224896755 skills qualities employers look data scientist\n",
      "16 0.7644062871503434 proficient data scientist coding\n",
      "17 0.512040877626451 rounds data scientist interview\n",
      "18 0.7361956881856189 mathematical background required data scientist\n",
      "\n",
      "\n",
      "Question:  is coding required for becoming data scientist \n",
      "\n",
      "\n",
      "Retrieved:  How proficient should a data scientist be in coding?\n",
      "Needs to be reasonably proficient. Again, a data scientist is a developer ++. Usually expected to have the basic skills a developer has including understanding algorithms and data structures and being able to write clean, understable, efficient, well documented code. \n",
      "\n",
      "In many cases, the data scientist is expected to write production ready code and be able to understand the deployment process. In some cases, the coding could be for decision support.\n"
     ]
    }
   ],
   "source": [
    "#With Word2Vec\n",
    "\n",
    "sent_embeddings=[];\n",
    "for sent in cleaned_sentences:\n",
    "    sent_embeddings.append(getPhraseEmbedding(sent,v2w_model));\n",
    "\n",
    "question_embedding=getPhraseEmbedding(question,v2w_model);\n",
    "\n",
    "calculate_similarity(question_embedding,sent_embeddings,df, cleaned_sentences);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove is an alternate approach to build word embeddings using matrix factorization techinques on the word-word co-occurance matrix.\n",
    "#### While both the techniques are popular, glove performs better on some datasets while word2vec skipgram model performs better on some. Here, I have experimented with both the word2vec and the glove models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.899116905528574 job hunting experience look like\n",
      "1 0.9336363898230245 valuable skills data scientist\n",
      "2 0.9081188685497033 average salary data scientist\n",
      "3 0.8141071793895427 algorithms data scientist toolbox\n",
      "4 0.9175146061047484 prepare data science interview\n",
      "5 0.8730817407502276 insights offer ds job market\n",
      "6 0.9004896812670068 employers look advanced ml degree\n",
      "7 0.9166257825507318 typical day data scientist look like\n",
      "8 0.9548748358557457 need prepare algorithms data structures data science interview\n",
      "9 0.9008804241466186 benefits data science certification\n",
      "10 0.9109423463126703 participate hackathons help getting job\n",
      "11 0.9658703837605412 need know statistics order land data science role\n",
      "12 0.93260344932244 career opportunities data science\n",
      "13 0.9561140665659048 common mistakes data science enthusiasts interview\n",
      "14 0.8268798168858132 s impact covid hiring ds roles\n",
      "15 0.9505724757994463 skills qualities employers look data scientist\n",
      "16 0.8539567220743777 proficient data scientist coding\n",
      "17 0.9204930055088648 rounds data scientist interview\n",
      "18 0.914017230818982 mathematical background required data scientist\n",
      "\n",
      "\n",
      "Question:  is coding required for becoming data scientist \n",
      "\n",
      "\n",
      "Retrieved:  Do I need to know statistics in order to land a data science role?\n",
      " Yes you need to know statistics in order to land a data science job. But don’t be afraid. You are not required to go through a master’s course in statistics. There a couple of topics/concepts that you must have commands on and you are good to go –\n",
      "\n",
      "Descriptive Statistics (mean, median, mode, variance, standard deviation)\n",
      "Inferential Statistics (hypothesis testing,  z test, t-test, significance level, p-value)\n",
      "Statistical analysis (linear regression, forecasting, logistic regression)\n"
     ]
    }
   ],
   "source": [
    "#With Glove\n",
    "\n",
    "sent_embeddings=[];\n",
    "for sent in cleaned_sentences:\n",
    "    sent_embeddings.append(getPhraseEmbedding(sent,glove_model));\n",
    "    \n",
    "question_embedding=getPhraseEmbedding(question,glove_model);\n",
    "\n",
    "calculate_similarity(question_embedding,sent_embeddings,df, cleaned_sentences);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
